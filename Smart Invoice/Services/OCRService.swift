import Foundation
import Vision
import VisionKit
import UIKit
import Combine
import CoreImage

/// OCR ƒ∞≈ülemlerinden sorumlu servis sƒ±nƒ±fƒ±.
/// Python projesindeki 'FaturaRegexAnaliz' sƒ±nƒ±fƒ±nƒ±n iOS kar≈üƒ±lƒ±ƒüƒ±dƒ±r.
class OCRService: ObservableObject, OCRServiceProtocol {
    
    @Published var recognizedText: String = ""
    @Published var isProcessing: Bool = false
    @Published var progress: Double = 0.0 // 0.0 - 1.0
    
    // Dependency Injection
    private let invoiceParser: InvoiceParserProtocol
    
    init(invoiceParser: InvoiceParserProtocol = InvoiceParser.shared) {
        self.invoiceParser = invoiceParser
    }
    
    /// G√∂r√ºnt√ºden metin okuma i≈ülemini ba≈ülatƒ±r (Apple Vision API)
    /// - Parameter image: Taranacak fatura g√∂r√ºnt√ºs√º
    /// - Returns: Parse edilmi≈ü Invoice
    /// - Throws: OCRServiceError
    func recognizeText(from image: UIImage) async throws -> Invoice {
        await MainActor.run {
            self.isProcessing = true
            self.progress = 0.0
        }
        
        print("üñºÔ∏è OCR ba≈ülƒ±yor, g√∂r√ºnt√º boyutu: \(image.size), scale: \(image.scale), orientation: \(image.imageOrientation.rawValue)")
        
        // G√∂r√ºnt√º orientation'ƒ±nƒ± d√ºzelt (galeri resimleri i√ßin √∂nemli)
        let orientedImage = image.fixedOrientation()
        
        guard let originalCGImage = orientedImage.cgImage else {
            await MainActor.run {
                self.isProcessing = false
                self.progress = 0.0
            }
            throw OCRServiceError.invalidImage
        }
        
        // Galeri g√∂rselleri i√ßin daha agresif preprocessing gerekebilir
        // Orientation d√ºzeltmesi yapƒ±ldƒ±, ≈üimdi preprocessing yapalƒ±m
        // √ñnce preprocessing yapƒ±lmƒ±≈ü g√∂r√ºnt√º ile OCR dene (galeri g√∂rselleri i√ßin √∂nemli)
        print("üîÑ ƒ∞lk deneme: Preprocessing yapƒ±lmƒ±≈ü g√∂r√ºnt√º ile OCR")
        let preprocessedImage = await preprocessImage(orientedImage)
        guard let preprocessedCGImage = preprocessedImage.cgImage else {
            await MainActor.run {
                self.isProcessing = false
                self.progress = 0.0
            }
            throw OCRServiceError.invalidImage
        }
        
        do {
            let result = try await performOCR(on: preprocessedCGImage, size: preprocessedImage.size, isRetry: false)
            return result
        } catch {
            print("‚ö†Ô∏è Preprocessing yapƒ±lmƒ±≈ü g√∂r√ºnt√º ile OCR ba≈üarƒ±sƒ±z, orijinal g√∂r√ºnt√º ile tekrar deneniyor...")
            
            // Preprocessing ba≈üarƒ±sƒ±z olduysa orijinal g√∂r√ºnt√º ile tekrar dene
            print("üîÑ ƒ∞kinci deneme: Orijinal g√∂r√ºnt√º ile OCR (preprocessing olmadan)")
            do {
                return try await performOCR(on: originalCGImage, size: orientedImage.size, isRetry: true)
            } catch {
                // Her iki deneme de ba≈üarƒ±sƒ±z, hatayƒ± fƒ±rlat
                print("‚ùå T√ºm OCR denemeleri ba≈üarƒ±sƒ±z")
                throw error
            }
        }
    }
    
    /// OCR i≈ülemini ger√ßekle≈ütirir
    private func performOCR(on cgImage: CGImage, size: CGSize, isRetry: Bool = false) async throws -> Invoice {
        // OCR ba≈ülƒ±yor (20% progress)
        await MainActor.run {
            self.progress = 0.2
        }
        
        // Vision request'i async/await ile sarmala
        return try await withCheckedThrowingContinuation { continuation in
            // ƒ∞stek olu≈ütur
            let request = VNRecognizeTextRequest { [weak self] request, error in
                guard let self = self else {
                    continuation.resume(throwing: OCRServiceError.processingError("Service deallocated"))
                    return
                }
                
                // Hata kontrol√º
                if let error = error {
                    Task { @MainActor in
                        self.isProcessing = false
                    }
                    continuation.resume(throwing: OCRServiceError.recognitionError(error.localizedDescription))
                    return
                }
                
                guard let observations = request.results as? [VNRecognizedTextObservation] else {
                    print("‚ùå OCR: Observations bulunamadƒ±")
                    Task { @MainActor in
                        self.isProcessing = false
                        self.progress = 0.0
                    }
                    continuation.resume(throwing: OCRServiceError.recognitionError("Metin bulunamadƒ±"))
                    return
                }
                
                print("‚úÖ OCR: \(observations.count) adet text observation bulundu")
                
                // OCR tamamlandƒ± (60% progress)
                Task { @MainActor in
                    self.progress = 0.6
                }
                
                // Okunan metinleri bloklara d√∂n√º≈üt√ºr
                let blocks: [TextBlock] = observations.compactMap { observation in
                    guard let candidate = observation.topCandidates(1).first else {
                        print("‚ö†Ô∏è OCR: Candidate bulunamadƒ±")
                        return nil
                    }
                    
                    // Vision koordinat sistemi (0,0 sol alt) -> UIKit (0,0 sol √ºst) d√∂n√º≈ü√ºm√º
                    // Vision'ƒ±n boundingBox'ƒ± sol alt k√∂≈üeden ba≈ülar, UIKit sol √ºst k√∂≈üeden ba≈ülar
                    let uikitFrame = TextBlock.convertVisionToUIKit(observation.boundingBox)
                    
                    return TextBlock(
                        text: candidate.string,
                        frame: uikitFrame, // UIKit koordinat sistemine d√∂n√º≈üt√ºr√ºlm√º≈ü (0-1 arasƒ±)
                        confidence: candidate.confidence // OCR confidence deƒüeri
                    )
                }
                
                print("‚úÖ OCR: \(blocks.count) adet TextBlock olu≈üturuldu")
                
                // Debug i√ßin ham metni de olu≈ütur
                let extractedText = blocks.map { $0.text }.joined(separator: "\n")
                print("üìù OCR: Ham metin uzunluƒüu: \(extractedText.count) karakter")
                
                if blocks.isEmpty && extractedText.isEmpty {
                    print("‚ùå OCR: Hem blocks hem de extractedText bo≈ü!")
                }
                
                Task { @MainActor in
                    self.recognizedText = extractedText
                    self.progress = 0.8 // Parsing ba≈ülƒ±yor
                }
                
                // Konumsal Analiz ile Parse Et
                Task {
                    do {
                        print("üîÑ Parser'a g√∂nderiliyor: \(blocks.count) blocks, \(extractedText.count) karakter metin")
                        let draftInvoice = try await self.invoiceParser.parse(blocks: blocks, rawText: extractedText)
                        
                        print("‚úÖ Parser ba≈üarƒ±lƒ±: \(draftInvoice.merchantName.isEmpty ? "Satƒ±cƒ± bulunamadƒ±" : "Satƒ±cƒ±: \(draftInvoice.merchantName)")")
                        
                        // Tamamlandƒ± (100% progress)
                        await MainActor.run {
                            self.progress = 1.0
                            self.isProcessing = false
                        }
                        
                        continuation.resume(returning: draftInvoice)
                    } catch {
                        print("‚ùå Parser hatasƒ±: \(error.localizedDescription)")
                        if let parserError = error as? InvoiceParserError {
                            print("   Parser error type: \(parserError)")
                        }
                        await MainActor.run {
                            self.isProcessing = false
                            self.progress = 0.0
                        }
                        continuation.resume(throwing: OCRServiceError.processingError(error.localizedDescription))
                    }
                }
            }
            
            // Maksimum doƒüruluk i√ßin Vision Framework ayarlarƒ±
            request.recognitionLanguages = ["tr-TR", "en-US"] // T√ºrk√ße ve ƒ∞ngilizce dil desteƒüi
            request.recognitionLevel = .accurate // En y√ºksek doƒüruluk seviyesi (hƒ±z yerine doƒüruluk)
            request.usesLanguageCorrection = true // Dil d√ºzeltmesi aktif
            request.minimumTextHeight = 0.0 // Minimum metin y√ºksekliƒüi (0 = otomatik, t√ºm metinleri yakala)
            // Not: customWords √∂zelliƒüi Vision Framework'te mevcut deƒüil, bu y√ºzden eklenmedi
            
            // Vision request options
            let options: [VNImageOption: Any] = [
                .ciContext: AppConstants.ciContext // Shared Core Image context
            ]
            
            // G√∂r√ºnt√º orientation'ƒ±nƒ± otomatik algƒ±la
            // Vision Framework orientation'ƒ± otomatik algƒ±layabilir, ama manuel belirtmek daha g√ºvenilir
            let requestHandler = VNImageRequestHandler(cgImage: cgImage, orientation: .up, options: options)
            
            print("üîç Vision request ayarlarƒ±:")
            print("   - Diller: \(request.recognitionLanguages)")
            print("   - Seviye: \(request.recognitionLevel == .accurate ? "accurate" : "fast")")
            print("   - Dil d√ºzeltmesi: \(request.usesLanguageCorrection)")
            print("   - G√∂r√ºnt√º boyutu: \(cgImage.width)x\(cgImage.height)")
            let colorSpaceName: String = (cgImage.colorSpace?.name as String?) ?? "bilinmiyor"
            print("   - G√∂r√ºnt√º color space: \(colorSpaceName)")
            print("   - G√∂r√ºnt√º bits per component: \(cgImage.bitsPerComponent)")
            print("   - G√∂r√ºnt√º bits per pixel: \(cgImage.bitsPerPixel)")
            
            // Arka planda √ßalƒ±≈ütƒ±r (UI donmasƒ±n diye)
            // Background queue kullanarak UI thread'ini bloklamadan OCR yap
            Task.detached(priority: .userInitiated) {
                do {
                    try requestHandler.perform([request])
                } catch {
                    await MainActor.run {
                        self.isProcessing = false
                        self.progress = 0.0
                    }
                    continuation.resume(throwing: OCRServiceError.recognitionError(error.localizedDescription))
                }
            }
        }
    }
    
    // MARK: - Image Preprocessing
    
    /// G√∂r√ºnt√ºy√º OCR i√ßin optimize eder
    /// - Parameter image: Orijinal g√∂r√ºnt√º
    /// - Returns: ƒ∞≈ülenmi≈ü g√∂r√ºnt√º
    private func preprocessImage(_ image: UIImage) async -> UIImage {
        let size = image.size
        let maxSize = max(size.width, size.height)
        
        // 1. Minimum boyut kontrol√º (OCR i√ßin en az 800px geni≈ülik/y√ºkseklik)
        let minDimension: CGFloat = 800
        let maxDimension: CGFloat = 3000
        
        // √áok k√º√ß√ºk g√∂r√ºnt√ºleri b√ºy√ºt
        if maxSize < minDimension {
            let scale = minDimension / maxSize
            let newSize = CGSize(width: size.width * scale, height: size.height * scale)
            print("üìè G√∂r√ºnt√º k√º√ß√ºk, b√ºy√ºt√ºl√ºyor: \(size) -> \(newSize)")
            let resized = await resizeImage(image, to: newSize)
            // K√º√ß√ºk g√∂r√ºnt√ºler i√ßin daha agresif iyile≈ütirme
            return await enhanceImage(resized)
        }
        
        // √áok b√ºy√ºk g√∂r√ºnt√ºleri k√º√ß√ºlt
        if maxSize > maxDimension {
            let scale = maxDimension / maxSize
            let newSize = CGSize(width: size.width * scale, height: size.height * scale)
            print("üìè G√∂r√ºnt√º b√ºy√ºk, k√º√ß√ºlt√ºl√ºyor: \(size) -> \(newSize)")
            let resized = await resizeImage(image, to: newSize)
            return await enhanceImageLight(resized)
        }
        
        // Boyut uygunsa, kontrast ve parlaklƒ±k iyile≈ütirmesi yap
        // Galeri resimleri i√ßin daha agresif iyile≈ütirme gerekebilir
        print("üìè G√∂r√ºnt√º boyutu uygun, iyile≈ütirme yapƒ±lƒ±yor")
        return await enhanceImage(image)
    }
    
    /// G√∂r√ºnt√ºy√º belirli boyuta resize eder
    private func resizeImage(_ image: UIImage, to newSize: CGSize) async -> UIImage {
        return await withCheckedContinuation { continuation in
            UIGraphicsBeginImageContextWithOptions(newSize, false, image.scale)
            defer { UIGraphicsEndImageContext() }
            
            image.draw(in: CGRect(origin: .zero, size: newSize))
            let resizedImage = UIGraphicsGetImageFromCurrentImageContext() ?? image
            continuation.resume(returning: resizedImage)
        }
    }
    
    /// G√∂r√ºnt√ºy√º gerekirse yeniden boyutlandƒ±rƒ±r
    private func resizeImageIfNeeded(_ image: UIImage, maxDimension: CGFloat) async -> UIImage {
        let size = image.size
        let maxSize = max(size.width, size.height)
        
        // Eƒüer g√∂r√ºnt√º zaten k√º√ß√ºkse, i≈ülem yapma
        if maxSize <= maxDimension {
            return image
        }
        
        // Aspect ratio'yu koruyarak resize et
        let scale = maxDimension / maxSize
        let newSize = CGSize(width: size.width * scale, height: size.height * scale)
        
        return await withCheckedContinuation { continuation in
            UIGraphicsBeginImageContextWithOptions(newSize, false, image.scale)
            defer { UIGraphicsEndImageContext() }
            
            image.draw(in: CGRect(origin: .zero, size: newSize))
            let resizedImage = UIGraphicsGetImageFromCurrentImageContext() ?? image
            continuation.resume(returning: resizedImage)
        }
    }
    
    /// G√∂r√ºnt√ºy√º hafif iyile≈ütirir (PDF g√∂r√ºnt√ºleri i√ßin)
    private func enhanceImageLight(_ image: UIImage) async -> UIImage {
        guard let ciImage = CIImage(image: image) else {
            return image
        }
        
        // Core Image filters
        // Core Image filters
        let context = AppConstants.ciContext
        
        // Hafif kontrast artƒ±rma (PDF g√∂r√ºnt√ºleri i√ßin daha az agresif)
        guard let contrastFilter = CIFilter(name: "CIColorControls") else {
            return image
        }
        contrastFilter.setValue(ciImage, forKey: kCIInputImageKey)
        contrastFilter.setValue(1.1, forKey: kCIInputContrastKey) // %10 kontrast artƒ±≈üƒ± (daha hafif)
        contrastFilter.setValue(1.05, forKey: kCIInputBrightnessKey) // %5 parlaklƒ±k artƒ±≈üƒ±
        
        guard let enhancedCI = contrastFilter.outputImage else {
            return image
        }
        
        return renderCIImage(enhancedCI, context: context, size: image.size) ?? image
    }
    
    /// G√∂r√ºnt√ºy√º iyile≈ütirir (kontrast, parlaklƒ±k) - Galeri resimleri i√ßin agresif iyile≈ütirme
    private func enhanceImage(_ image: UIImage) async -> UIImage {
        guard let ciImage = CIImage(image: image) else {
            print("‚ö†Ô∏è CIImage olu≈üturulamadƒ±, orijinal g√∂r√ºnt√º d√∂nd√ºr√ºl√ºyor")
            return image
        }
        
        // Core Image filters
        // Core Image filters
        let context = AppConstants.ciContext
        var currentImage = ciImage
        
        // 1. G√ºr√ºlt√º azaltma (galeri g√∂rselleri i√ßin √∂nemli)
        if let noiseReductionFilter = CIFilter(name: "CINoiseReduction") {
            // Set input image
            noiseReductionFilter.setValue(currentImage, forKey: kCIInputImageKey)
            // CINoiseReduction uses keys: inputNoiseLevel and inputSharpness
            // Use typed properties when available, otherwise fall back to string keys
            if noiseReductionFilter.responds(to: Selector(("setInputNoiseLevel:"))) {
                // No direct setter available via Swift, keep KVC with proper key names
                noiseReductionFilter.setValue(0.02, forKey: "inputNoiseLevel")
            } else {
                noiseReductionFilter.setValue(0.02, forKey: "inputNoiseLevel")
            }
            if noiseReductionFilter.responds(to: Selector(("setInputSharpness:"))) {
                noiseReductionFilter.setValue(0.4, forKey: "inputSharpness")
            } else {
                noiseReductionFilter.setValue(0.4, forKey: "inputSharpness")
            }
            if let output = noiseReductionFilter.outputImage {
                currentImage = output
                print("‚úÖ G√ºr√ºlt√º azaltma uygulandƒ±")
            }
        }
        
        // 2. Kontrast ve parlaklƒ±k artƒ±rma (galeri resimleri i√ßin daha agresif)
        guard let contrastFilter = CIFilter(name: "CIColorControls") else {
            print("‚ö†Ô∏è CIColorControls filter bulunamadƒ±")
            return image
        }
        contrastFilter.setValue(currentImage, forKey: kCIInputImageKey)
        contrastFilter.setValue(1.4, forKey: kCIInputContrastKey) // %40 kontrast artƒ±≈üƒ± (daha agresif)
        contrastFilter.setValue(1.15, forKey: kCIInputBrightnessKey) // %15 parlaklƒ±k artƒ±≈üƒ±
        contrastFilter.setValue(1.1, forKey: kCIInputSaturationKey) // %10 doygunluk artƒ±≈üƒ±
        
        guard let enhancedCI = contrastFilter.outputImage else {
            print("‚ö†Ô∏è Enhanced CIImage olu≈üturulamadƒ±")
            return image
        }
        currentImage = enhancedCI
        
        // 3. Sharpening ekle (metin okunabilirliƒüini artƒ±rƒ±r - daha agresif)
        if let sharpenFilter = CIFilter(name: "CISharpenLuminance") {
            sharpenFilter.setValue(currentImage, forKey: kCIInputImageKey)
            // CISharpenLuminance uses keys: inputSharpness and inputRadius
            sharpenFilter.setValue(0.6, forKey: kCIInputSharpnessKey)
            sharpenFilter.setValue(0.4, forKey: kCIInputRadiusKey)
            if let sharpenedCI = sharpenFilter.outputImage {
                currentImage = sharpenedCI
                print("‚úÖ Sharpening uygulandƒ±")
            }
        }
        
        // 4. Exposure d√ºzeltmesi (galeri g√∂rselleri i√ßin)
        if let exposureFilter = CIFilter(name: "CIExposureAdjust") {
            exposureFilter.setValue(currentImage, forKey: kCIInputImageKey)
            exposureFilter.setValue(0.2, forKey: kCIInputEVKey) // Hafif exposure artƒ±≈üƒ±
            
            if let exposedCI = exposureFilter.outputImage {
                currentImage = exposedCI
                print("‚úÖ Exposure d√ºzeltmesi uygulandƒ±")
            }
        }
        
        return renderCIImage(currentImage, context: context, size: image.size) ?? image
    }
    
    /// CIImage'i UIImage'e d√∂n√º≈üt√ºr√ºr
    private func renderCIImage(_ ciImage: CIImage, context: CIContext, size: CGSize) -> UIImage? {
        guard let cgImage = context.createCGImage(ciImage, from: ciImage.extent) else {
            return nil
        }
        return UIImage(cgImage: cgImage, scale: 1.0, orientation: .up)
    }
}

// MARK: - UIImage Extension for Orientation Fix

extension UIImage {
    /// G√∂r√ºnt√º orientation'ƒ±nƒ± d√ºzeltir (galeri resimleri i√ßin)
    func fixedOrientation() -> UIImage {
        // Eƒüer orientation .up ise, d√∂n√º≈ü√ºm gerekmez
        if imageOrientation == .up {
            return self
        }
        
        // Orientation'ƒ± d√ºzelt
        UIGraphicsBeginImageContextWithOptions(size, false, scale)
        defer { UIGraphicsEndImageContext() }
        
        draw(in: CGRect(origin: .zero, size: size))
        return UIGraphicsGetImageFromCurrentImageContext() ?? self
    }
}
